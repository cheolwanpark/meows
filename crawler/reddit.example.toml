# Example configuration for Reddit crawler
# Usage: cat reddit.example.toml | cargo run -- --keywords "async" --keywords "tokio"

[crawler]
# User-Agent header for HTTP requests (REQUIRED by Reddit API)
# Format: "appname/version (by /u/yourusername)" or similar
user_agent = "crawler/0.1.0 (by /u/your_username)"

# Where to write the output: "stdout" or a file path like "/tmp/output.json"
# Can be overridden with --output flag
output_destination = "stdout"

# Maximum number of sources to fetch from concurrently
max_concurrency = 5

# Log level: error, warn, info, debug, trace
log_level = "info"

# Reddit source configuration

[[sources]]
type = "reddit"
enabled = true
subreddit = "rust"               # Target subreddit (without /r/ prefix)
limit = 100                       # Number of posts to fetch (supports pagination)
sort_by = "hot"                   # Sorting: "hot", "new", "top", or "rising"
min_score = 0                     # Filter posts below this score
min_comments = 0                  # Filter posts with fewer comments
user_agent = "crawler/0.1.0"      # User-Agent for this source
rate_limit_delay_ms = 1000        # Delay between paginated requests (milliseconds)

# Example: Another subreddit with different settings

[[sources]]
type = "reddit"
enabled = false
subreddit = "programming"
limit = 50
sort_by = "new"
min_score = 10
min_comments = 2
user_agent = "crawler/0.1.0"
rate_limit_delay_ms = 1000

# Example: Fetching top posts of the week

[[sources]]
type = "reddit"
enabled = false
subreddit = "rust"
limit = 100
sort_by = "top"
time_filter = "week"              # REQUIRED when sort_by="top": hour, day, week, month, year, all
min_score = 50
min_comments = 10
user_agent = "crawler/0.1.0"
rate_limit_delay_ms = 1000

# Usage examples:
# cat reddit.example.toml | cargo run -- --keywords "async" --keywords "tokio"
# cat reddit.example.toml | cargo run -- --keywords "tutorial" --match-mode all --output results.json
